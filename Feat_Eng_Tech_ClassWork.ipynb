{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550f61c7-27e6-46e2-a4d4-a4f68cd86d97",
   "metadata": {},
   "source": [
    "### Various Feature Engineering Techniques, each relevant to the banking sector:\n",
    "\n",
    "### 1. **Imputation**\n",
    "\n",
    "**Scenario:** A bank's dataset has missing values in the `Credit_Score` column, and we need to handle these missing values.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- **Original Data:**\n",
    "  - `Customer_ID`\n",
    "  - `Credit_Score`\n",
    "\n",
    "- **Feature Engineering:**\n",
    "  - **Imputation:** Use the mean of the `Credit_Score` column to fill missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a23204-08f1-49d3-aa7d-0a6716b812dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_ID  Credit_Score\n",
      "0            1         650.0\n",
      "1            2         675.0\n",
      "2            3         700.0\n",
      "3            4         675.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Customer_ID': [1, 2, 3, 4],\n",
    "    'Credit_Score': [650, None, 700, None]\n",
    "})\n",
    "\n",
    "# Imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['Credit_Score'] = imputer.fit_transform(df[['Credit_Score']])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0f472-8dca-4086-8966-b7393b301081",
   "metadata": {},
   "source": [
    "### 2. **Binning**\n",
    "\n",
    "**Scenario:** A bank wants to categorize `Annual_Income` into income brackets.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- **Original Feature:**\n",
    "  - `Annual_Income`\n",
    "\n",
    "- **Feature Engineering:**\n",
    "  - **Binning:** Create income brackets (e.g., `Low`, `Medium`, `High`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e72ccb-600e-4268-b42f-68f8fc6c0329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Annual_Income Income_Bracket\n",
      "0          30000            Low\n",
      "1          50000         Medium\n",
      "2          70000           High\n",
      "3          90000      Very High\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Annual_Income': [30000, 50000, 70000, 90000]\n",
    "})\n",
    "\n",
    "# Feature Binning\n",
    "bins = [0, 40000, 60000, 80000, float('inf')]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "df['Income_Bracket'] = pd.cut(df['Annual_Income'], bins=bins, labels=labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61fe36b-365f-4f31-b3c6-ac1923814729",
   "metadata": {},
   "source": [
    "### 3. **Ordinary Encoding**\n",
    "\n",
    "**Scenario:** Encode the `Employment_Status` column with ordinal values.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- **Original Feature:**\n",
    "  - `Employment_Status` (e.g., `Self-Employed`, `Employed`, `Unemployed`)\n",
    "\n",
    "- **Feature Engineering:**\n",
    "  - **Ordinary Encoding:** Assign numerical values to ordinal categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a654d3f9-b0b6-4242-b221-563c4cf5e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Employment_Status  Employment_Status_Encoded\n",
      "0     Self-Employed                          2\n",
      "1          Employed                          1\n",
      "2        Unemployed                          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Employment_Status': ['Self-Employed', 'Employed', 'Unemployed']\n",
    "})\n",
    "\n",
    "# Ordinal Encoding\n",
    "ordinal_map = {'Unemployed': 0, 'Employed': 1, 'Self-Employed': 2}\n",
    "df['Employment_Status_Encoded'] = df['Employment_Status'].map(ordinal_map)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ec950-db45-4af7-992d-3de788d95c02",
   "metadata": {},
   "source": [
    "### 4. **One-Hot Encoding**\n",
    "\n",
    "**Scenario:** Encode the `Loan_Type` column into binary features.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- **Original Feature:**\n",
    "  - `Loan_Type` (e.g., `Home Loan`, `Auto Loan`, `Personal Loan`)\n",
    "\n",
    "- **Feature Engineering:**\n",
    "  - **One-Hot Encoding:** Convert categorical feature into binary columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "315987cf-d5d3-4c02-9fcc-87d6b8cf945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loan_Type_Auto Loan  Loan_Type_Home Loan  Loan_Type_Personal Loan\n",
      "0                False                 True                    False\n",
      "1                 True                False                    False\n",
      "2                False                False                     True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Loan_Type': ['Home Loan', 'Auto Loan', 'Personal Loan']\n",
    "})\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['Loan_Type'])\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012bf62c-02da-448e-b1f2-64062e41f14a",
   "metadata": {},
   "source": [
    "### 5. **Feature Splitting**\n",
    "\n",
    "**Scenario:** Split `Transaction_Date` into `Year` and `Month`.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- **Original Feature:**\n",
    "  - `Transaction_Date`\n",
    "\n",
    "- **Feature Engineering:**\n",
    "  - **Feature Splitting:** Extract year and month from date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8505e51a-cb0c-4be3-a5f1-9d7fc7d8b06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transaction_Date  Year  Month\n",
      "0       2024-01-01  2024      1\n",
      "1       2024-02-15  2024      2\n",
      "2       2024-03-20  2024      3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Transaction_Date': pd.to_datetime(['2024-01-01', '2024-02-15', '2024-03-20'])\n",
    "})\n",
    "\n",
    "# Feature Splitting\n",
    "df['Year'] = df['Transaction_Date'].dt.year\n",
    "df['Month'] = df['Transaction_Date'].dt.month\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d015652-7860-40ed-8663-2d47c85f9ae9",
   "metadata": {},
   "source": [
    "### 6. **Handling Outliers**\n",
    "\n",
    "**Scenario:** Identify and handle outliers in the `Transaction_Amount` column.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- **Original Feature:**\n",
    "  - `Transaction_Amount`\n",
    "\n",
    "- **Feature Engineering:**\n",
    "  - **Handling Outliers:** Remove outliers using the IQR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40b54127-12e7-4d57-8b0f-df56758db494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction_Amount\n",
      "0                 100\n",
      "1                 200\n",
      "2                 300\n",
      "4                 500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Transaction_Amount': [100, 200, 300, 10000, 500]\n",
    "})\n",
    "\n",
    "# Handling Outliers using IQR\n",
    "Q1 = df['Transaction_Amount'].quantile(0.25)\n",
    "Q3 = df['Transaction_Amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_no_outliers = df[(df['Transaction_Amount'] >= (Q1 - 1.5 * IQR)) & (df['Transaction_Amount'] <= (Q3 + 1.5 * IQR))]\n",
    "print(df_no_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9baf18-dec4-4653-a08c-e10675ae69c5",
   "metadata": {},
   "source": [
    "### 7. **Transformations**\n",
    "\n",
    "**Scenario:** Apply transformations to `Transaction_Amount` to handle skewness.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- **Original Feature:**\n",
    "  - `Transaction_Amount`\n",
    "\n",
    "- **Feature Engineering:**\n",
    "  - **Transformation:** Apply log transformation to reduce skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddc4e90e-4c99-4a96-927b-ff15ea60d77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction_Amount  Log_Transaction_Amount\n",
      "0                 100                4.615121\n",
      "1                 200                5.303305\n",
      "2                 300                5.707110\n",
      "3               10000                9.210440\n",
      "4                 500                6.216606\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Transaction_Amount': [100, 200, 300, 10000, 500]\n",
    "})\n",
    "\n",
    "# Feature Transformation\n",
    "df['Log_Transaction_Amount'] = np.log(df['Transaction_Amount'] + 1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbdfac1-4fef-4a26-a342-7aad4d847be5",
   "metadata": {},
   "source": [
    "### 8. **Scaling (Normalization & Standardization)**\n",
    "\n",
    "**Scenario:** Normalize and standardize features for machine learning models.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- **Original Features:**\n",
    "  - `Annual_Income`\n",
    "  - `Total_Debt`\n",
    "\n",
    "- **Feature Engineering:**\n",
    "  - **Normalization:** Scale features to a range [0, 1].\n",
    "  - **Standardization:** Scale features to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c9bd48-9810-444c-ad21-4dc52a886adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Data:\n",
      "   Annual_Income  Total_Debt\n",
      "0            0.0         0.0\n",
      "1            0.5         0.5\n",
      "2            1.0         1.0\n",
      "\n",
      "Standardized Data:\n",
      "   Annual_Income  Total_Debt\n",
      "0      -1.224745   -1.224745\n",
      "1       0.000000    0.000000\n",
      "2       1.224745    1.224745\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Annual_Income': [30000, 50000, 70000],\n",
    "    'Total_Debt': [10000, 20000, 30000]\n",
    "})\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "print(\"Normalized Data:\")\n",
    "print(df_normalized)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "print(\"\\nStandardized Data:\")\n",
    "print(df_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6faddc7-d9aa-4f49-b2dd-058c569b42a3",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- **Imputation:** Filling missing values using the mean.\n",
    "- **Binning:** Categorizing continuous variables into bins.\n",
    "- **Ordinary Encoding:** Encoding ordinal categorical variables.\n",
    "- **One-Hot Encoding:** Converting categorical variables into binary columns.\n",
    "- **Feature Splitting:** Breaking down features into more granular parts.\n",
    "- **Handling Outliers:** Removing outliers using the IQR method.\n",
    "- **Transformations:** Applying transformations like log to reduce skewness.\n",
    "- **Scaling:** Normalizing and standardizing features for model training.\n",
    "\n",
    "These examples cover a range of feature engineering techniques applicable to banking and finance data, helping to prepare data for better model performance and insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
